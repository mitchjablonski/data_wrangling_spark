{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling with Spark SQL Quiz\n",
    "\n",
    "This quiz uses the same dataset and most of the same questions from the earlier \"Quiz - Data Wrangling with Data Frames Jupyter Notebook.\" For this quiz, however, use Spark SQL instead of Spark Data Frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import desc\n",
    "from pyspark.sql.functions import asc\n",
    "from pyspark.sql.functions import sum as Fsum\n",
    "\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Data wrangling with Spark SQL\") \\\n",
    "    .getOrCreate()\n",
    "path = \"data/sparkify_log_small.json\"\n",
    "user_log = spark.read.json(path)\n",
    "user_log.createOrReplaceTempView(\"user_log_table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "Which page did user id \"\"(empty string) NOT visit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Row(page='Downgrade'),\n",
       " Row(page='Error'),\n",
       " Row(page='Logout'),\n",
       " Row(page='NextSong'),\n",
       " Row(page='Save Settings'),\n",
       " Row(page='Settings'),\n",
       " Row(page='Submit Downgrade'),\n",
       " Row(page='Submit Upgrade'),\n",
       " Row(page='Upgrade')}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_string_set = set(spark.sql('''\n",
    "          SELECT DISTINCT(page)\n",
    "          FROM user_log_table \n",
    "          WHERE userID == ''\n",
    "          '''\n",
    "          ).collect())\n",
    "nominal_set = set(spark.sql('''\n",
    "          SELECT DISTINCT(page)\n",
    "          FROM user_log_table\n",
    "          '''\n",
    "          ).collect())\n",
    "nominal_set - empty_string_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 - Reflect\n",
    "\n",
    "Why might you prefer to use SQL over data frames? Why might you prefer data frames over SQL?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Depending on the level of control needed, and the level of expertise on the team, utilizing a SQL interface to Spark could be far simpler.  If we need more control, we may need to utilize the data frame interface to Spark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "\n",
    "How many female users do we have in the data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(count(DISTINCT userID)=462, gender='F'),\n",
       " Row(count(DISTINCT userID)=1, gender=None),\n",
       " Row(count(DISTINCT userID)=501, gender='M')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('''\n",
    "          SELECT count(DISTINCT(userID)), gender\n",
    "          FROM user_log_table\n",
    "          GROUP BY gender\n",
    "          '''\n",
    "          ).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(count(DISTINCT userID)=462)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('''\n",
    "          SELECT count(DISTINCT(userID))\n",
    "          FROM user_log_table\n",
    "          WHERE gender = 'F'\n",
    "          '''\n",
    "          ).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "\n",
    "How many songs were played from the most played artist?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|count(1)|              artist|\n",
      "+--------+--------------------+\n",
      "|    1653|                null|\n",
      "|      83|            Coldplay|\n",
      "|      69|       Kings Of Leon|\n",
      "|      52|Florence + The Ma...|\n",
      "|      46|            BjÃÂ¶rk|\n",
      "|      45|       Dwight Yoakam|\n",
      "|      43|       Justin Bieber|\n",
      "|      40|      The Black Keys|\n",
      "|      37|         OneRepublic|\n",
      "|      36|                Muse|\n",
      "|      36|        Jack Johnson|\n",
      "|      31|           Radiohead|\n",
      "|      29|        Taylor Swift|\n",
      "|      28|Barry Tuckwell/Ac...|\n",
      "|      28|          Lily Allen|\n",
      "|      28|               Train|\n",
      "|      27|           Daft Punk|\n",
      "|      27|           Metallica|\n",
      "|      27|          Nickelback|\n",
      "|      26|          Kanye West|\n",
      "+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "          SELECT count(*), artist\n",
    "          FROM user_log_table\n",
    "          GROUP BY artist\n",
    "          ORDER BY count(*) DESC\n",
    "          '''\n",
    "          ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|count(1)|              artist|\n",
      "+--------+--------------------+\n",
      "|      83|            Coldplay|\n",
      "|      69|       Kings Of Leon|\n",
      "|      52|Florence + The Ma...|\n",
      "|      46|            BjÃÂ¶rk|\n",
      "|      45|       Dwight Yoakam|\n",
      "|      43|       Justin Bieber|\n",
      "|      40|      The Black Keys|\n",
      "|      37|         OneRepublic|\n",
      "|      36|        Jack Johnson|\n",
      "|      36|                Muse|\n",
      "|      31|           Radiohead|\n",
      "|      29|        Taylor Swift|\n",
      "|      28|               Train|\n",
      "|      28|Barry Tuckwell/Ac...|\n",
      "|      28|          Lily Allen|\n",
      "|      27|           Daft Punk|\n",
      "|      27|           Metallica|\n",
      "|      27|          Nickelback|\n",
      "|      26|          Kanye West|\n",
      "|      24|Red Hot Chili Pep...|\n",
      "+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "          SELECT count(*), artist\n",
    "          FROM user_log_table\n",
    "          WHERE artist IS NOT NULL\n",
    "          GROUP BY artist\n",
    "          ORDER BY count(*) DESC\n",
    "          '''\n",
    "          ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5 (challenge)\n",
    "\n",
    "How many songs do users listen to on average between visiting our home page? Please round your answer to the closest integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_results = spark.sql(\"\"\"SELECT userID, page, ts, CASE WHEN page = 'Home' THEN 1 ELSE 0 END AS \n",
    "                       page_status FROM user_log_table \n",
    "                       WHERE (page = 'NextSong') or (page = 'Home') \n",
    "                    \"\"\")\n",
    "\n",
    "home_results.createOrReplaceTempView(\"home_results_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_sum = spark.sql(\"\"\"SELECT *, SUM(page_status) OVER \n",
    "                            (PARTITION BY userID ORDER BY ts DESC ROWS BETWEEN \n",
    "                                    UNBOUNDED PRECEDING AND CURRENT ROW) AS period \n",
    "                              FROM home_results_table\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-------------+-----------+------+\n",
      "|userID|    page|           ts|page_status|period|\n",
      "+------+--------+-------------+-----------+------+\n",
      "|  1436|NextSong|1513783259284|          0|     0|\n",
      "|  1436|NextSong|1513782858284|          0|     0|\n",
      "|  2088|    Home|1513805972284|          1|     1|\n",
      "|  2088|NextSong|1513805859284|          0|     1|\n",
      "|  2088|NextSong|1513805494284|          0|     1|\n",
      "|  2088|NextSong|1513805065284|          0|     1|\n",
      "|  2088|NextSong|1513804786284|          0|     1|\n",
      "|  2088|NextSong|1513804555284|          0|     1|\n",
      "|  2088|NextSong|1513804196284|          0|     1|\n",
      "|  2088|NextSong|1513803967284|          0|     1|\n",
      "|  2088|NextSong|1513803820284|          0|     1|\n",
      "|  2088|NextSong|1513803651284|          0|     1|\n",
      "|  2088|NextSong|1513803413284|          0|     1|\n",
      "|  2088|NextSong|1513803254284|          0|     1|\n",
      "|  2088|NextSong|1513803057284|          0|     1|\n",
      "|  2088|NextSong|1513802824284|          0|     1|\n",
      "|  2162|NextSong|1513781246284|          0|     0|\n",
      "|  2162|NextSong|1513781065284|          0|     0|\n",
      "|  2162|NextSong|1513780860284|          0|     0|\n",
      "|  2162|NextSong|1513780569284|          0|     0|\n",
      "+------+--------+-------------+-----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cumulative_sum.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the results in a view\n",
    "cumulative_sum.createOrReplaceTempView(\"period_of_use\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|avg(count_results)|\n",
      "+------------------+\n",
      "| 6.898347107438017|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# find the average count for NextSong\n",
    "spark.sql(\"\"\"SELECT AVG(count_results) FROM \n",
    "          (SELECT COUNT(*) AS count_results FROM period_of_use \n",
    "          GROUP BY userID, period, page HAVING page = 'NextSong') AS counts\"\"\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
